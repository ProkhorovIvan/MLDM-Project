{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prokhorov Ivan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.pylabtools import figsize\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (135,204,274,417) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9  ...  f770  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  ...     5   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  ...     6   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  ...    13   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  ...     4   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  ...    26   \n",
       "\n",
       "   f771  f772  f773    f774    f775  f776  f777  f778  loss  \n",
       "0  2.14 -1.54  1.18  0.1833  0.7873     1     0     5     0  \n",
       "1  0.54 -0.24  0.13  0.1926 -0.6787     1     0     5     0  \n",
       "2  2.89 -1.73  1.04  0.2521  0.7258     1     0     5     0  \n",
       "3  1.29 -0.89  0.66  0.2498  0.7119     1     0     5     0  \n",
       "4  6.11 -3.82  2.51  0.2282 -0.5399     0     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105289.000000</td>\n",
       "      <td>105370.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>104407.000000</td>\n",
       "      <td>103946.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>134.603171</td>\n",
       "      <td>8.246883</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>2678.488874</td>\n",
       "      <td>7.354533</td>\n",
       "      <td>47993.704317</td>\n",
       "      <td>2974.336018</td>\n",
       "      <td>2436.363718</td>\n",
       "      <td>134.555225</td>\n",
       "      <td>...</td>\n",
       "      <td>17.422543</td>\n",
       "      <td>5.800976</td>\n",
       "      <td>-4.246788</td>\n",
       "      <td>3.273059</td>\n",
       "      <td>0.233852</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>0.310246</td>\n",
       "      <td>0.322847</td>\n",
       "      <td>175.951589</td>\n",
       "      <td>0.799585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30446.999458</td>\n",
       "      <td>14.725467</td>\n",
       "      <td>1.691535</td>\n",
       "      <td>0.288752</td>\n",
       "      <td>1401.010943</td>\n",
       "      <td>5.151112</td>\n",
       "      <td>35677.136048</td>\n",
       "      <td>2546.551085</td>\n",
       "      <td>2262.950221</td>\n",
       "      <td>13.824682</td>\n",
       "      <td>...</td>\n",
       "      <td>18.548936</td>\n",
       "      <td>6.508555</td>\n",
       "      <td>4.828265</td>\n",
       "      <td>3.766746</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>1.039439</td>\n",
       "      <td>0.462597</td>\n",
       "      <td>0.467567</td>\n",
       "      <td>298.294043</td>\n",
       "      <td>4.321120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.439600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26368.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.248950</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11255.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>124.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>-5.700000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>-0.704275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76530.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>128.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79103.500000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.749494</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80135.000000</td>\n",
       "      <td>4679.000000</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>149.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-1.010000</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>88565.000000</td>\n",
       "      <td>9968.000000</td>\n",
       "      <td>11541.000000</td>\n",
       "      <td>172.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.040000</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>11.092000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id             f1             f2             f3  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean    52736.000000     134.603171       8.246883       0.499066   \n",
       "std     30446.999458      14.725467       1.691535       0.288752   \n",
       "min         1.000000     103.000000       1.000000       0.000006   \n",
       "25%     26368.500000     124.000000       8.000000       0.248950   \n",
       "50%     52736.000000     129.000000       9.000000       0.498267   \n",
       "75%     79103.500000     148.000000       9.000000       0.749494   \n",
       "max    105471.000000     176.000000      11.000000       0.999994   \n",
       "\n",
       "                  f4             f5             f6             f7  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
       "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
       "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
       "min      1100.000000       1.000000       0.000000       1.000000   \n",
       "25%      1500.000000       4.000000   11255.000000     629.000000   \n",
       "50%      2200.000000       4.000000   76530.000000    2292.000000   \n",
       "75%      3700.000000      10.000000   80135.000000    4679.000000   \n",
       "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
       "\n",
       "                  f8             f9  ...           f770           f771  \\\n",
       "count  105370.000000  105471.000000  ...  105471.000000  105471.000000   \n",
       "mean     2436.363718     134.555225  ...      17.422543       5.800976   \n",
       "std      2262.950221      13.824682  ...      18.548936       6.508555   \n",
       "min         1.000000     106.820000  ...       2.000000       0.000000   \n",
       "25%       746.000000     124.290000  ...       5.000000       1.480000   \n",
       "50%      1786.000000     128.460000  ...      11.000000       3.570000   \n",
       "75%      3411.000000     149.080000  ...      23.000000       7.700000   \n",
       "max     11541.000000     172.950000  ...     168.000000      58.120000   \n",
       "\n",
       "                f772           f773           f774           f775  \\\n",
       "count  105471.000000  105471.000000  104407.000000  103946.000000   \n",
       "mean       -4.246788       3.273059       0.233852       0.014797   \n",
       "std         4.828265       3.766746       0.073578       1.039439   \n",
       "min       -43.160000       0.000000       0.000000     -18.439600   \n",
       "25%        -5.700000       0.740000       0.198400      -0.704275   \n",
       "50%        -2.600000       1.990000       0.251800       0.375400   \n",
       "75%        -1.010000       4.440000       0.283600       0.737100   \n",
       "max         0.000000      34.040000       0.473700      11.092000   \n",
       "\n",
       "                f776           f777           f778           loss  \n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000  \n",
       "mean        0.310246       0.322847     175.951589       0.799585  \n",
       "std         0.462597       0.467567     298.294043       4.321120  \n",
       "min         0.000000       0.000000       2.000000       0.000000  \n",
       "25%         0.000000       0.000000      19.000000       0.000000  \n",
       "50%         0.000000       0.000000      40.000000       0.000000  \n",
       "75%         1.000000       1.000000     104.000000       0.000000  \n",
       "max         1.000000       1.000000    1212.000000     100.000000  \n",
       "\n",
       "[8 rows x 752 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 771)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.select_dtypes(include=['object']).columns:\n",
    "    data.drop(labels=i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Distribution')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "figsize=(8, 8)\n",
    "\n",
    "# Histogram of the loss\n",
    "\n",
    "plt.hist(data['loss'], bins = 100, edgecolor = 'k')\n",
    "plt.xlabel('Loss') \n",
    "plt.ylabel('Number of Clients');\n",
    "plt.title('Loss Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f612   -0.016943\n",
      "f776   -0.015111\n",
      "f315   -0.011106\n",
      "f70    -0.010740\n",
      "f314   -0.010689\n",
      "f323   -0.010676\n",
      "f69    -0.010269\n",
      "f322   -0.009299\n",
      "f734   -0.009284\n",
      "f738   -0.008635\n",
      "f1     -0.008162\n",
      "f631   -0.008097\n",
      "f428   -0.007973\n",
      "f666   -0.007868\n",
      "f299   -0.007778\n",
      "Name: loss, dtype: float64 \n",
      "\n",
      "f674    0.018999\n",
      "f536    0.026087\n",
      "f471    0.039538\n",
      "loss    1.000000\n",
      "f33          NaN\n",
      "f34          NaN\n",
      "f35          NaN\n",
      "f37          NaN\n",
      "f38          NaN\n",
      "f678         NaN\n",
      "f700         NaN\n",
      "f701         NaN\n",
      "f702         NaN\n",
      "f736         NaN\n",
      "f764         NaN\n",
      "Name: loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "correlations_data = data.corr()['loss'].sort_values()\n",
    "\n",
    "\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if len(set(data[i]))==1:\n",
    "        data.drop(labels=[i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f612   -0.016943\n",
      "f776   -0.015111\n",
      "f315   -0.011106\n",
      "f70    -0.010740\n",
      "f314   -0.010689\n",
      "f323   -0.010676\n",
      "f69    -0.010269\n",
      "f322   -0.009299\n",
      "f734   -0.009284\n",
      "f738   -0.008635\n",
      "f1     -0.008162\n",
      "f631   -0.008097\n",
      "f428   -0.007973\n",
      "f666   -0.007868\n",
      "f299   -0.007778\n",
      "Name: loss, dtype: float64 \n",
      "\n",
      "f282    0.010726\n",
      "f251    0.010915\n",
      "f221    0.010968\n",
      "f556    0.011575\n",
      "f675    0.011606\n",
      "f13     0.011933\n",
      "f68     0.013375\n",
      "f599    0.014165\n",
      "f597    0.014165\n",
      "f670    0.014811\n",
      "f67     0.015012\n",
      "f674    0.018999\n",
      "f536    0.026087\n",
      "f471    0.039538\n",
      "loss    1.000000\n",
      "Name: loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find all correlations and sort \n",
    "correlations_data = data.corr()['loss'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 156)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Feature Engineering and Selection\n",
    "\n",
    "def remove_col_cols(x, threshold):\n",
    "\n",
    "    y = x['loss']\n",
    "    x = x.drop(columns = ['loss'])\n",
    "    \n",
    "\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "           \n",
    "            if val >= threshold:\n",
    "\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    \n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns = drops)\n",
    "  \n",
    "    x['loss'] = y\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_col_cols(data, 0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['loss','id'])\n",
    "id_train = data['id']\n",
    "targets = pd.DataFrame(data['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (417) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "intersection_cols = df.columns & data.columns\n",
    "res = df[intersection_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df['id']\n",
    "res = res.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "res = sc.fit_transform(res)\n",
    "# X_test = sc.transform(X_test)\n",
    "train = sc.fit_transform(features)\n",
    "train_target = np.array(targets).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "random.fit(features, targets)\n",
    "random_pred = random.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Иван\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:02:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "gb = XGBClassifier()\n",
    "gb.fit(train, train_target)\n",
    "gb_predict = gb.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_random = pd.DataFrame({'id': test_id, 'loss': random_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_gb = pd.DataFrame({'id': test_id, 'loss': gb_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_random.to_csv('sumbission_random_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_gb.to_csv('sumbission_gb_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
